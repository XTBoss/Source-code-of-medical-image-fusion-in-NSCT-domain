# Image-Fusion
Image fusion method
Source code of article 
“A Phase Congruency and Local Laplacian Energy based Multi-modality Medical Image Fusion Method in NSCT Domain”

By Zhiqin Zhu and Mingyao Zheng

Zhiqin Zhu, Mingyao Zheng, Guanqiu Qi, Di Wang, Yang Xiang
A Phase Congruency and Local Laplacian Energy Based Multi-Modality Medical Image Fusion Method in NSCT Domain.[J]. IEEE Access, 2019(7):20811-20824.

BIBTEX:

@ARTICLE{8636953, 
author={Z. {Zhu} and M. {Zheng} and G. {Qi} and D. {Wang} and Y. {Xiang}}, 
journal={IEEE Access}, 
title={A Phase Congruency and Local Laplacian Energy Based Multi-Modality Medical Image Fusion Method in NSCT Domain}, 
year={2019}, 
volume={7}, 
number={}, 
pages={20811-20824}, 
}

Abstract{
Multi-modality image fusion provides more comprehensive and sophisticated information in modern medical diagnosis, 
remote sensing, video surveillance, and so on. This paper presents a novel multi-modality medical image fusion 
method based on phase congruency and local Laplacian energy. In the proposed method, the non-subsampled contourlet 
transform is performed on medical image pairs to decompose the source images into high-pass and low-pass subbands. 
The high-pass subbands are integrated by a phase congruency-based fusion rule that can enhance the detailed features of 
the fused image for medical diagnosis. A local Laplacian energy-based fusion rule is proposed for low-pass subbands. 
The local Laplacian energy consists of weighted local energy and the weighted sum of Laplacian coefficients that 
describe the structured information and the detailed features of source image pairs, respectively. 
Thus, the proposed fusion rule can simultaneously integrate two key components for the fusion of low-pass subbands. 
The fused high-pass and low-pass subbands are inversely transformed to obtain the fused image. 
In the comparative experiments, three categories of multi-modality medical image pairs are used to verify 
the effectiveness of the proposed method. The experiment results show that the proposed method achieves competitive 
performance in both the image quantity and computational costs.}, 
doi={10.1109/ACCESS.2019.2898111}, 
ISSN={2169-3536}, 

